{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Diffusion\n",
    "\n",
    "## Introduction\n",
    "\n",
    "One of the key ideas of diffusion models is the forward diffusion process involved.\n",
    "By adding Gaussian noise to an input over a series of timesteps,\n",
    "we're able to move the initial image to a latent space that approaches a Gaussian distribution.\n",
    "\n",
    "In this notebook, we'll be seeing the effects of different choices of variance schedules.\n",
    "The variance schedule will determine the variances of the noise we're adding to the image over time.\n",
    "What happens when we choose the variance to be higher? What about lower?\n",
    "\n",
    "We'll be exploring the effects of these choices by visualizing the state over the diffusion process,\n",
    "and hopefully get a sense for how they relate to the rate at which this movement from\n",
    "the original image / distribution to the latent Gaussian distribution occurs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library imports\n",
    "\n",
    "Before you begin, you'll need to set up your environment.\n",
    "\n",
    "### If you're running locally:\n",
    "\n",
    "To set up a new environment that contains the necessary libraries,\n",
    "you can run the startup script by running `bash startup.sh`.\n",
    "\n",
    "Double check that you are now in the `env-proj` conda environment that was created.\n",
    "If not, run `conda activate env-proj` in your terminal.\n",
    "\n",
    "### If you're running on Colab\n",
    "\n",
    "Please change the following cell from `%matplotlib widget` to `%matplotlib inline`.\n",
    "since Colab does not currently seem to support `ipympl` or `widget` out of the box.\n",
    "(It may be able to support the `widget` mode but more setup for that may be required.)\n",
    "\n",
    "### Double check\n",
    "\n",
    "Make sure that the following libraries have been installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import jit, random, Array\n",
    "from jax.config import config\n",
    "config.update(\"jax_debug_nans\", True)\n",
    "config.update(\"jax_array\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A: Mean and Covariance of Diffusion\n",
    "\n",
    "Implement the forward diffusion process according to the formulas specified in problem (1) of the homework, specifically the mean and covariance of the forward process posterior Normal distribution. \n",
    "Run the cells immediately following to test your implementation.\n",
    "\n",
    "**Note:**\n",
    "If you run into issues or errors that mention `jit`,\n",
    "feel free to comment out the `@jit` decorator at the top of the functions.\n",
    "The `@jit` decorator is not needed for correctness, but may help speed up the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean(x: Array, var: Array) -> Array:\n",
    "    mean = None # REPLACE WITH YOUR CODE HERE\n",
    "    return mean\n",
    "\n",
    "def compute_cov(x: Array, var: Array) -> Array:\n",
    "    n = x.shape[0]\n",
    "    cov = None # REPLACE WITH YOUR CODE HERE\n",
    "    return cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test your implementation\n",
    "\n",
    "The following cells will test your implementation of the mean and covariance functions.\n",
    "While there may be slight differences due to floating point accuracy,\n",
    "your implementation should fall within the allowed error range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_cases import run_diffusion_mean_tests, run_diffusion_cov_tests\n",
    "run_diffusion_mean_tests(compute_mean)\n",
    "run_diffusion_cov_tests(compute_cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing states over time\n",
    "\n",
    "Now that we've verified the correctness of the calculated mean and covariance,\n",
    "let's visualize how the states get diffused over time.\n",
    "\n",
    "First, we'll want to set up the diffusion process by sampling from the multivariate\n",
    "Gaussian normal that is characterized by our mean and covariance functions,\n",
    "where we call `diffuse` to diffuse the state over a single timestep.\n",
    "We will then want to repeat this over the length of the variance schedule,\n",
    "as seen in `diffuse_over_time`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def diffuse(key, x: Array, var: Array) -> Array:\n",
    "    \"\"\"\n",
    "    Given (flattened) x, sample x diffused with Gaussian noise\n",
    "    according to the variance schedule.\n",
    "    \"\"\"\n",
    "    mean = compute_mean(x, var)\n",
    "    cov = compute_cov(x, var)\n",
    "    return random.multivariate_normal(key, mean, cov)\n",
    "\n",
    "@jit\n",
    "def diffuse_over_time(key, x: Array, var_schedule: Array) -> List[Array]:\n",
    "    states = [x]\n",
    "    shape = x.shape\n",
    "    x = x.flatten()\n",
    "    for t in jnp.arange(var_schedule.shape[0]):\n",
    "        key, subkey = random.split(key)\n",
    "        x = diffuse(subkey, x, var_schedule[t])\n",
    "        states.append(x.reshape(shape))\n",
    "    return states\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these functions defined, we can now visualize how the identity matrix gets diffused over time,\n",
    "according to each variance schedule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import show_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = jnp.eye(3)\n",
    "\n",
    "var_schedules = [\n",
    "    jnp.array([0.01, 0.01, 0.01]),\n",
    "    jnp.array([0.1, 0.2, 0.5]),\n",
    "    jnp.array([0.5, 0.2, 0.1]),\n",
    "    jnp.array([0.99, 0.99, 0.99]),\n",
    "]\n",
    "\n",
    "key = random.PRNGKey(0)\n",
    "for var_schedule in var_schedules:\n",
    "    states = diffuse_over_time(key, x, var_schedule)\n",
    "    show_plots(states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, can you come up with an interesting input `x` and one or more interesting variance schedules?\n",
    "**Define your input and add variance schedules below.**\n",
    "\n",
    "You can then run the cell to visualize your input being diffused\n",
    "according to the variance schedules you proposed.\n",
    "\n",
    "What kind of observations do you have?\n",
    "What happens when you make the variances very high?\n",
    "How about very low?\n",
    "What if you alternate?\n",
    "Can you still see traces of the original input's patterns in the final diffused state?\n",
    "What about in the intermediate diffused states?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = None # REPLACE WITH YOUR SOLUTION HERE\n",
    "\n",
    "var_schedules = [\n",
    "    # YOUR CODE HERE\n",
    "]\n",
    "\n",
    "key = random.PRNGKey(1)\n",
    "for var_schedule in var_schedules:\n",
    "    states = diffuse_over_time(key, x, var_schedule)\n",
    "    show_plots(states)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Comparing the JIT and non-JIT versions of the diffusion process\n",
    "\n",
    "You may have noticed the `@jit` decorator above the `diffuse` function earlier in this notebook.\n",
    "`jax` provides `jit` as a way to speed up user-defined functions.\n",
    "Here, we'll be comparing the performance of `diffuse` and its non-JIT version `diffuse_nojit`.\n",
    "\n",
    "Run the following cell to see the difference in speed between `diffuse`\n",
    "(that has been sped up by `jit`) and `diffuse_nojit` which has not had that speedup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An interesting comparison in timing between\n",
    "# non-JIT and JIT versions of the diffuse function\n",
    "\n",
    "def diffuse_nojit(key, x, var):\n",
    "    \"\"\"\n",
    "    Given (flattened) x, sample x diffused with Gaussian noise\n",
    "    according to the variance schedule.\n",
    "    \"\"\"\n",
    "    mean = compute_mean(x, var)\n",
    "    cov = compute_cov(x, var)\n",
    "    return random.multivariate_normal(key, mean, cov)\n",
    "\n",
    "key = random.PRNGKey(0)\n",
    "x = jnp.eye(3).flatten()\n",
    "\n",
    "print(\"Timing for JIT diffuse:\")\n",
    "%timeit diffuse(key, x, 0.01)\n",
    "\n",
    "print(\"Timing for non-JIT diffuse:\")\n",
    "%timeit diffuse_nojit(key, x, 0.01)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When diffusion is used in training larger models, the computation time can either\n",
    "help or hurt over the course of long training loops.\n",
    "So even a small speedup for a inner function like `diffusion` can help in the\n",
    "long run, since the forward diffusion process is applied on every input during\n",
    "training.\n",
    "\n",
    "However, since our homework deals with only small, toy examples,\n",
    "the difference is not really necessary but simply interesting to note.\n",
    "The difference may also be more or less significant based upon whether you're\n",
    "running this locally or in Colab (where you and `jax` can take advantage of\n",
    "accelerators such as GPUs for even faster computation).\n",
    "\n",
    "Later on this homework, we'll be training a model for the *denoising* process,\n",
    "and speedups will help us even there, where our inputs are still small."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "74da0d11463147640a4316afec5e99a6a6eb153ba7d9ca6562a169804ac9f9ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
