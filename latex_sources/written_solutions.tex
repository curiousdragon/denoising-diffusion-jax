\documentclass{article}
\usepackage[T1]{fontenc}
\usepackage{parskip}
\usepackage{amssymb, amsmath, graphicx, subfigure}
\usepackage[dvipsnames]{xcolor}

\DeclareMathOperator{\EX}{\mathbb{E}}% expected value

\setlength{\oddsidemargin}{.25in}
\setlength{\evensidemargin}{.25in}
\setlength{\textwidth}{6in}
\setlength{\topmargin}{-0.4in}
\setlength{\textheight}{8.5in}

\newcommand{\heading}[6]{
  \renewcommand{\thepage}{#1-\arabic{page}}
  \noindent
  \begin{center}
  \framebox{
    \vbox{
      \hbox to 5.78in { \textbf{#2} \hfill #3 }
      \vspace{4mm}
      \hbox to 5.78in { {\Large \hfill #6  \hfill} }
      \vspace{2mm}
      \hbox to 5.78in { \textit{Instructor: #4 \hfill #5} }
    }
  }
  \end{center}
  \vspace*{4mm}
}

\newtheorem{theorem}{Theorem}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{observation}[theorem]{Observation}
\newtheorem{fact}[theorem]{Fact}
\newtheorem{assumption}[theorem]{Assumption}

\newenvironment{proof}{\noindent{\bf Proof:} \hspace*{1mm}}{
	\hspace*{\fill} $\Box$ }
\newenvironment{proof_of}[1]{\noindent {\bf Proof of #1:}
	\hspace*{1mm}}{\hspace*{\fill} $\Box$ }
\newenvironment{proof_claim}{\begin{quotation} \noindent}{
	\hspace*{\fill} $\diamond$ \end{quotation}}

\newcommand{\problemset}[3]{\heading{#1}{CS182/282A: Deep Neural Nets}{#2}{Anant Sahai}{#3}{Diffusion, Denoising, and Deep Networks}}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% PLEASE MODIFY THESE FIELDS AS APPROPRIATE
\newcommand{\problemsetnum}{1}          % problem set number
\newcommand{\duedate}{December 7, 2022}  % problem set deadline
\newcommand{\studentname}{Jamie Hong, Michael Lam, Mark Lindblad, Anze Liu}    % 

\renewcommand{\cite}[1]{[#1]}
\def\beginrefs{\begin{list}%
        {[\arabic{equation}]}{\usecounter{equation}
         \setlength{\leftmargin}{2.0truecm}\setlength{\labelsep}{0.4truecm}%
         \setlength{\labelwidth}{1.6truecm}}}
\def\endrefs{\end{list}}
\def\bibentry#1{\item[\hbox{[#1]}]}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

\problemset{\problemsetnum}{\duedate}{\studentname}


\setcounter{section}{-1}
\section{Introduction}

In this assignment, we'll investigate how diffusion models work, involving:
\begin{enumerate}
    \item the forward process where we add randomly sampled Gaussian noise to an input via a Markov Chain of diffusion steps,
    \item analyzing different loss functions,
    \item and followed by exploring how to reverse the diffusion process by denoising and generate new samples from the original predicted distribution.
\end{enumerate}

\begin{figure}[!h]
    \centering
    \includegraphics[width=12cm]{forward_backward.png}
    \caption{Forward Diffusion Process and Reverse Denoising Process}
    \label{fig:ForwardBackward}
\end{figure}

\section{Forward ``Noising'' Process}
Diffusion networks are neural networks that progressively ``denoise'' an input, e.g. image, that has been corrupted with Gaussian noise until the original input is reconstructed. This can be thought of as a two-pass Markov chain with $T$ nodes. In the forward (first) pass, noise is added from state to state, which can be described by the following posterior: 
\begin{equation}
    q(\textbf{x}_{1:T}|\textbf{x}_{0}) := \prod_{t=1}^{T} q(\textbf{x}_{t}|\textbf{x}_{t - 1}),\;\;\;\;\;q(\textbf{x}_{t}|\textbf{x}_{t - 1}) := N(\textbf{x}_{t}; \sqrt{1 - \beta_{t}}\textbf{x}_{t-1}, \beta_{t} \textbf{I})
\end{equation}
where $\textbf{x}_{0}$ is the initial image, and each subsequent step $\textbf{x}_{t}$ is a ``noised'' version of the image at the previous time step. $\beta_{1}$...$\beta_{T}$ is the \textit{variance schedule} because it controls how much each image at each time step is diffused; qualitatively, the higher the sampling variance $\beta_{t}$, the more unrecognizable an image will be after the diffusion at that time step. 




\noindent In this problem, we will be exploring how to implement this forward diffusion pass through the Markov chain. The rest of the problems will be dedicated to the \textit{reverse} pass, where the image will be progressively \textit{denoised} until the resulting image will be close to the initial image $\textbf{x}_{0}$.

\begin{enumerate}
\item
\textbf{What happens when all the variances are 0? What do the images look like at each time step? What about when all the variances are 1?}

% Answer:
\textcolor{blue}{
    \textbf{Solution: } 
    When all the variances $\beta_t$'s are 0, that tells us that we're sampling from a distribution whose only possible value is its mean value $\sqrt{1-\beta_t}\mathbf{x}_{t-1}$. Under these conditions, the mean simplifies to $\mathbf{x}_{t-1}$. In other words, there is no change in the state across timesteps. Whatever state we started at initially at $\mathbf{x}_0$ will be the same state at any other timestep, i.e. $\mathbf{x}_t=\mathbf{x}_0$. Intuitively, this also makes since we're saying there should be \textit{no} variation in our sampled values from the mean. So the images will look the same at every time step, as no noise is being added to vary our images.
}

\textcolor{blue}{
    When all the variances $\beta_t$'s are 1, the mean of our distribution becomes $\mathbf{0}$. Essentially we lose all information about our original input image, and just sample directly from an i.i.d. standard normal distribution, where the mean is 0 and the variances are all 1's. Although the initial state will look like itself (i.e. from the interesting distribution of the inputs), all other states should look like random Gaussian noise.
}

\item
In the \verb|diffusion.ipynb| Jupyter notebook, implement the \verb|compute_mean| and \verb|compute_cov| functions. Run the following cells to test your implementation. Then follow the instructions in the notebook to define your own input and variance schedules to visualize.

% Answer:
\textcolor{blue}{
    \textbf{Solution: } 
    See the diffusion Jupyter notebook for coding solutions.
}

\item
Once you have implemented the functions above, the code allows you to run the forward diffusion pass with a number of different variance schedules. Play around with these parameters and try testing different kinds of variance schedules. \textbf{How does the variance scheduling affect the rate at which the initial image becomes unrecognizable? What patterns do you notice?}

% Answer:
\textcolor{blue}{
    \textbf{Solution: } 
    See the diffusion Jupyter notebook for coding solutions.
    The student should observe that a variance schedule with close to 0 variance leads to very little diffusion as the sampling process becomes close to deterministic. Contrarily, a diffusion schedule where $\beta_t$ is close to 1 for all $t$ should render the initial image unrecognizable in very few iterations.
}

\item
In practice, we often want to calculate the Gaussian noise at a time step $t$ conditioned on the initial time step rather than the previous time step. \textbf{Given equation (1), derive a closed-form expression for $q(\textbf{x}_{T}|\textbf{x}_{0})$} and \textbf{show your work}. 

(Hint: Define variables $\alpha_t := 1 - \beta_t$ and $\bar\alpha_t := \prod_{s = 1}^{t}\alpha_s$.)

% Answer:
\textcolor{blue}{
    \textbf{Solution: } 
    \begin{align*}
        q(\textbf{x}_{t}|\textbf{x}_{t - 1}) := N(\textbf{x}_{t}; \sqrt{1 - \beta_{t}}\textbf{x}_{t-1}, \beta_{t} \textbf{I})
    \end{align*}
        For all $\epsilon \sim\ N(0, I)$
    \begin{align*}
        \textbf{x}_t &= \sqrt{1 - \beta_{t}}\textbf{x}_{t-1} + \sqrt{\beta_{t}}\epsilon_{t-1} \\
        &= \sqrt{\alpha_{t}}\textbf{x}_{t-1} + \sqrt{1 - \alpha_{t}}\epsilon_{t-1}\\
    \end{align*}
        Adding two Gaussians $\epsilon_{t-1} \sim\ N(0, (1-\alpha_t)\textbf{I})$ and $\epsilon_{t-2} \sim\ N(0, \alpha_t(1-\alpha_{t-1})\textbf{I})$ \\
        results in $\hat{\epsilon}_{t-2} \sim\ N(0, \left[(1-\alpha_t)+\alpha_t(1-\alpha_{t-1})\right]\textbf{I})$
    \begin{align*}
        \textbf{x}_t &= \sqrt{\alpha_{t}}\sqrt{\alpha_{t-1}}\textbf{x}_{t-2} + \sqrt{1 - \alpha_t + \alpha_t(1 - \alpha_{t-1})}\hat{\epsilon}_{t-2} \\
        &= \sqrt{\alpha_{t}}\sqrt{\alpha_{t-1}}\textbf{x}_{t-2} + \sqrt{1 - \alpha_t\alpha_{t-1}}\hat{\epsilon}_{t-2} \\
        &= ... \\
        &= \sqrt{\bar{\alpha}_t}\textbf{x}_0 + \sqrt{1 - \bar{\alpha}_t}\epsilon
    \end{align*}
    \begin{align*}
        q(\textbf{x}_{T}|\textbf{x}_{0}) = N(\textbf{x}_t; \sqrt{\Bar{\alpha}_t}\textbf{x}_0, (1 - \Bar{\alpha}_t)\textbf{I})
    \end{align*}
    Note that this distribution has the unique property that, when scaled down by a factor $\sqrt{\Bar{\alpha}_t}$, it becomes a Gaussian distribution centered at $\textbf{x}_0$ with unit variance.
}

\end{enumerate}
\section{Optimization Loss Function}
We will now study the reverse ``denoising'' pass of the diffusion network. The joint distribution $p_{\theta}(\textbf{x}_{0:T})$ is the reverse process, represented by a Markov chain with learned Gaussian transitions $p_{\theta}(\textbf{x}_{t-1}|\textbf{x}_t)$ for $t = 1, ..., T$:
\begin{equation}
    p_{\theta}(\textbf{x}_{0:T}) := p(\textbf{x}_{T})\prod_{t=1}^{T} p_{\theta}(\textbf{x}_{t-1}|\textbf{x}_{t}),\;\;\;\;\;p_{\theta}(\textbf{x}_{t-1}|\textbf{x}_{t}) := N(\textbf{x}_{t-1}; {\mu}_{\theta}(\textbf{x}_t, t), {\Sigma}_{\theta}(\textbf{x}_t, t))
\end{equation}
To optimize the reverse pass, we need to define an appropriate loss function for the final ``denoised'' state. In other words, given an end state $\textbf{x}_{t}$, we would like to estimate the most likely initial state, i.e. the state $\textbf{x}_0$ with the highest probability $p_{\theta}(\textbf{x}_0)$. This is equivalent to finding the minimum of the negative log likelihood:
\begin{equation}
    \EX[-log \; p_{\theta}(\textbf{x}_0)]
\end{equation}
We would like to find a distribution that approximates the random variable so we can generate data via sampling to predict probabilities at different time steps. \textit{Variational bound} (also known as the \textit{evidence lower bound}) allows us to upper bound the above negative log likelihood as such:
\begin{equation}
    \EX\left[-log \; p(\textbf{x}_0)\right] \; \leq \; \EX_q\left[-log \; \frac{p_{\theta}(\textbf{x}_{0:T})}{q(\textbf{x}_{1:T}|\textbf{x}_0)}\right] =: L
\end{equation}
We define the variational bound as our loss function. 

\begin{enumerate}
\item
\textbf{Show that the following expression is equivalent to the variational bound on the negative log likelihood:}
\begin{equation}
    \EX_q\left[-log \; p_{\theta}(\textbf{x}_T) - \sum_{t=1}^{T} log\;\frac{p_{\theta}(\textbf{x}_{t-1}|\textbf{x}_t)}{q(\textbf{x}_t|\textbf{x}_{t-1})} \right]
\end{equation}
% Answer:
\textcolor{blue}{
    \textbf{Solution: } 
    \begin{align*}
        \EX_q\left[-\log\frac{p_\theta(\textbf{x}_{0:T})}{q(\textbf{x}_{1:T}|\textbf{x}_0)}\right]
        &= \EX_q\left[-\log\frac{p(\textbf{x}_T)\displaystyle\prod_{t=1}^{T}
        p_\theta(\textbf{x}_{t-1}|\textbf{x}_t)}{\displaystyle\prod_{t=1}^{T}q(\textbf{x}_t|\textbf{x}_{t-1})}\right] \\
        &= \EX_q\left[-\log{p(\textbf{x}_T)} - \log\displaystyle\prod_{t=1}^{T}{
        \frac{p_\theta(\textbf{x}_{t-1}|\textbf{x}_t)}{q(\textbf{x}_t|\textbf{x}_{t-1})}}\right] \\
        &= \EX_q\left[-\log{p(\textbf{x}_T)} - \sum_{t=1}^{T}{\log
        \frac{p_\theta(\textbf{x}_{t-1}|\textbf{x}_t)}{q(\textbf{x}_t|\textbf{x}_{t-1})}}\right]
    \end{align*}
}
\item
For performance reasons, we would like to rewrite the upper bound derived in (2.1) as the \textit{KL divergence} between the posterior distribution of Gaussian noise and the probability of a given state. The KL divergence between P and Q measures the ``surprise'' from sampling from distribution Q when the actual population distribution is P. Mathematically, it is defined as the following:
\begin{equation}
    D_{KL}(P||Q) \; := \;\sum_{x\in\chi}P(x)\;log\;\frac{P(x)}{Q(x)}
\end{equation}

\begin{enumerate}
\item
\textbf{First prove the following equation.}
(Hint: Define $q(\textbf{x}_{t-1}|\textbf{x}_t, \textbf{x}_0)$ using conditional probability.)
\begin{equation}
    q(\textbf{x}_t|\textbf{x}_{t-1}) = \frac{q(\textbf{x}_{t-1}|\textbf{x}_t, \textbf{x}_0) q(\textbf{x}_t|\textbf{x}_0)}{q(\textbf{x}_{t-1}|\textbf{x}_0)}
\end{equation}
% Answer:
\textcolor{blue}{
    \textbf{Solution: } 
    \begin{align*}
        q(\textbf{x}_{t-1}|\textbf{x}_t, \textbf{x}_0) 
        &= \frac{q(\textbf{x}_t, \textbf{x}_{t-1}, \textbf{x}_0)}{q(\textbf{x}_t, \textbf{x}_0)} \\
        &= \frac{q(\textbf{x}_t, \textbf{x}_{t-1} | \textbf{x}_0)q(\textbf{x}_0)}{q(\textbf{x}_t, \textbf{x}_0)} \\
        &= \frac{q(\textbf{x}_t, \textbf{x}_{t-1} | \textbf{x}_0)}{q(\textbf{x}_t | \textbf{x}_0)} \\
        &= \frac{q(\textbf{x}_t|\textbf{x}_{t-1})q(\textbf{x}_{t-1}|\textbf{x}_0)}{q(\textbf{x}_t | \textbf{x}_0)}
    \end{align*}
    \begin{align*}
        q(\textbf{x}_t|\textbf{x}_{t-1}) 
        &= \frac{q(\textbf{x}_{t-1}|\textbf{x}_t, \textbf{x}_0) q(\textbf{x}_t|\textbf{x}_0)}{q(\textbf{x}_{t-1}|\textbf{x}_0)}
    \end{align*}
}

\item
\textbf{Using the above equation, show that (5) is equivalent to the following expression:}
(Hint: use the properties of logarithms.)
\begin{equation}
    \EX_q[D_{KL}(q(\textbf{x}_T|\textbf{x}_0) \; || \; p(\textbf{x}_T)) + \sum_{t>1}D_{KL}(q(\textbf{x}_{t-1}|\textbf{x}_t, \textbf{x}_0)\;||\;p_{\theta}(\textbf{x}_{t-1} | \textbf{x}_t)) - log \;p_{\theta}(\textbf{x}_0 | \textbf{x}_1)]
\end{equation}
% Answer:
\textcolor{blue}{
    \textbf{Solution: } 
    \begin{align*}
        L &= \EX_q\left[-\log{p(\textbf{x}_T)} 
        - \sum_{t=1}^{T}{\log\frac{p_\theta(\textbf{x}_{t-1}|\textbf{x}_t)}
        {q(\textbf{x}_t|\textbf{x}_{t-1})}}\right] \\
        &= \EX_q\left[-\log{p(\textbf{x}_T)} 
        - \sum_{t=2}^{T}{\log\frac{p_\theta(\textbf{x}_{t-1}|\textbf{x}_t)}{q(\textbf{x}_t|\textbf{x}_{t-1})}} 
        - \log\frac{p_\theta(\textbf{x}_0|\textbf{x}_1)}{q(\textbf{x}_1|\textbf{x}_0)} \right] \\
        &= \EX_q\left[-\log{p(\textbf{x}_T)} 
        - \sum_{t=2}^{T}{\log\frac{p_\theta(\textbf{x}_{t-1}|\textbf{x}_t)q(\textbf{x}_{t-1}|\textbf{x}_0)}
        {q(\textbf{x}_{t-1}|\textbf{x}_t, \textbf{x}_0) q(\textbf{x}_t|\textbf{x}_0)}} 
        - \log\frac{p_\theta(\textbf{x}_0|\textbf{x}_1)}{q(\textbf{x}_1|\textbf{x}_0)} \right] \:\:\:\:from\:part\:(a)\\
        &= \EX_q\left[-\log{p(\textbf{x}_T)} 
        - \sum_{t=2}^{T}{\log\frac{p_\theta(\textbf{x}_{t-1}|\textbf{x}_t)}
        {q(\textbf{x}_{t-1}|\textbf{x}_t, \textbf{x}_0)}} 
        - \sum_{t=2}^{T}{\log\frac{q(\textbf{x}_{t-1}|\textbf{x}_0)}
        {q(\textbf{x}_t|\textbf{x}_0)}} 
        - \log\frac{p_\theta(\textbf{x}_0|\textbf{x}_1)}{q(\textbf{x}_1|\textbf{x}_0)} \right] \\
        &= \EX_q\left[-\log{p(\textbf{x}_T)} 
        - \sum_{t=2}^{T}{\log\frac{p_\theta(\textbf{x}_{t-1}|\textbf{x}_t)}
        {q(\textbf{x}_{t-1}|\textbf{x}_t, \textbf{x}_0)}} 
        - \log\prod_{t=2}^{T}{\frac{q(\textbf{x}_{t-1}|\textbf{x}_0)}
        {q(\textbf{x}_t|\textbf{x}_0)}} 
        - \log\frac{p_\theta(\textbf{x}_0|\textbf{x}_1)}{q(\textbf{x}_1|\textbf{x}_0)} \right] \\
        &= \EX_q\left[-\log{p(\textbf{x}_T)} 
        - \sum_{t=2}^{T}{\log\frac{p_\theta(\textbf{x}_{t-1}|\textbf{x}_t)}
        {q(\textbf{x}_{t-1}|\textbf{x}_t, \textbf{x}_0)}} 
        - \log\frac{q(\textbf{x}_1|\textbf{x}_0)}
        {q(\textbf{x}_T|\textbf{x}_0)}
        - \log\frac{p_\theta(\textbf{x}_0|\textbf{x}_1)}{q(\textbf{x}_1|\textbf{x}_0)} \right] \\
        &= \EX_q\left[-\log{p(\textbf{x}_T)} 
        - \sum_{t=2}^{T}{\log\frac{p_\theta(\textbf{x}_{t-1}|\textbf{x}_t)}
        {q(\textbf{x}_{t-1}|\textbf{x}_t, \textbf{x}_0)}} 
        + \log{q(\textbf{x}_T|\textbf{x}_0)}
        - \log{p_\theta(\textbf{x}_0|\textbf{x}_1)} \right] \\
        &= \EX_q\left[-\log\frac{p(\textbf{x}_T)}{q(\textbf{x}_T|\textbf{x}_0)}
        - \sum_{t=2}^{T}{\log\frac{p_\theta(\textbf{x}_{t-1}|\textbf{x}_t)}
        {q(\textbf{x}_{t-1}|\textbf{x}_t, \textbf{x}_0)}} 
        - \log{p_\theta(\textbf{x}_0|\textbf{x}_1)} \right] \\
        &= \EX_q\left[D_{KL}(q(\textbf{x}_T|\textbf{x}_0)\vert \vert p(\textbf{x}_T)) 
        + \sum_{t=2}^{T}{D_{KL}(q(\textbf{x}_{t-1}|\textbf{x}_t, \textbf{x}_0) \vert \vert p_\theta(\textbf{x}_{t-1}|\textbf{x}_t)} 
        - \log{p_\theta(\textbf{x}_0|\textbf{x}_1)} \right]
    \end{align*}
}

\end{enumerate}

\end{enumerate}

\section{Reverse ``Denoising'' Process}
Notice that the loss function, when written in the KL divergence form, involves a Gaussian posterior probability conditioned on $\textbf{x}_t$ and $\textbf{x}_0$. It can be shown that this distribution is actually tractable and has the following closed form:
\begin{equation}
    q(\textbf{x}_{t-1}|\textbf{x}_t, \textbf{x}_0) = N(\textbf{x}_{t-1}; {\Tilde\mu_t}(\textbf{x}_t, \textbf{x}_0), \Tilde{\beta_t}\boldsymbol{I})
\end{equation}
where
\begin{equation}
    \Tilde{\mu}_t(\textbf{x}_t, \textbf{x}_0) := \frac{\sqrt{\Bar{\alpha}_{t-1}}\beta_t}{1 - \Bar{\alpha}_{t}}\textbf{x}_0 \; + \; \frac{\sqrt{\alpha_t}(1 - \Bar{\alpha}_{t-1})}{1 - \Bar{\alpha}_{t}}\textbf{x}_t \;\;\;\;\;\;\;\;\;\; \Tilde{\beta}_t := \frac{1 - \Bar{\alpha}_{t-1}}{1 - \Bar{\alpha}_{t}}\beta_t
\end{equation}
and both $\alpha_t$ and $\Bar{\alpha}_{t}$ are defined the same as in problem (1.4).

To establish the diffusion model, we need to choose the variances $\beta_t$ for the forward process. To establish the denoising process, we need to choose a parameterization of the Gaussian distribution for the reverse process. We can then define a loss function using the parameterized distribution to construct a model. 

To simplify implementation and improve computation efficiency, instead of directly computing the KL divergence loss on the target distribution $q$ and predicted distribution $p_\theta$, we choose to use the Mean Squared Error of $\Tilde{\mu}_t(x_t, x_0)$ (mean of target distribution) and $\mu_\theta(x_t, t)$ (mean of predicted distribution) as the training loss to obtain $p_\theta$, which approximates $q$. 

Revisiting $p_{\theta}(\textbf{x}_{t-1}|\textbf{x}_{t}) :=  N(\textbf{x}_{t-1};\;{\mu}_{\theta}(\textbf{x}_t, t),\;{\Sigma}(\textbf{x}_t, t))$ from (2), assume the variance is known from the variance scheduler and define ${\Sigma_\theta}(\textbf{x}_t, t) := {\sigma}_{t}^2\boldsymbol{I}$. 

The objective is to find a reverse process distribution $p_{\theta}(\textbf{x}_{t-1}|\textbf{x}_{t}) := N(\textbf{x}_{t-1}; {\mu}_{\theta}(\textbf{x}_t, t),  {\sigma}_{t}^2\boldsymbol{I})$ such that ${\mu}_{\theta}$ predicts the posterior mean $\Tilde{\mu_t}$ of the forward process $q(\textbf{x}_{t-1}|\textbf{x}_t, \textbf{x}_0) = N(\textbf{x}_{t-1};\;\Tilde{\mu_t}(\textbf{x}_t, \textbf{x}_0),\; \Tilde{\beta_t}\boldsymbol{I})$. 

Define the loss at time $t-1$ as:
\begin{equation}
    L_{t-1} := \EX_q\left[\frac{1}{2{\sigma_t}^2}
    \Big\lVert {\Tilde\mu_t}(\textbf{x}_t, \textbf{x}_0) - {\mu_\theta}(\textbf{x}_t, t)\Big\rVert^2\right] + C
\end{equation}
where C is a constant independent on $\theta$. 

\begin{enumerate}
    \item 
    Using the following reparameterization of your answer to (1.3), 
    
    ${x_t}(x_0, \epsilon) = \sqrt{\bar\alpha_t}x_0 + \sqrt{1 - \bar\alpha_t}\epsilon $  for $\epsilon \sim N(\boldsymbol{0}, \boldsymbol{I})$, 
    
    \textbf{Rewrite the loss (11) in terms of ${x_t}(x_0, \epsilon)$ (do not use $\Tilde\mu_t$).}

    % Answer:
\textcolor{blue}{
    \textbf{Solution: } 
    \begin{align*}
    L_{t-1} - C &= \EX_q\left[\frac{1}{2{\sigma_t}^2}
    \Big\lVert{\Tilde\mu_t}(\textbf{x}_t, \textbf{x}_0) - {\mu_\theta}(\textbf{x}_t, \textbf{x}_0)\Big\rVert^2\right] \\
    &= \EX_{\textbf{x}_0, \epsilon}\left[\frac{1}{2{\sigma_t}^2}
    \Big\lVert{\Tilde\mu_t}(\textbf{x}_t(\textbf{x}_0, \epsilon), \textbf{x}_0) - {\mu_\theta}(\textbf{x}_t(\textbf{x}_0, \epsilon), t)\Big\rVert^2\right] \\
    &= \EX_{\textbf{x}_0, \epsilon}\left[\frac{1}{2{\sigma_t}^2}
    \Big\lVert{\Tilde\mu_t}(\textbf{x}_t(\textbf{x}_0, \epsilon), \frac{1}{\sqrt{\Bar{\alpha}_t}}(\textbf{x}_t(\textbf{x}_0, \epsilon) - \sqrt{1 - \Bar{\alpha}_t}\epsilon)) - {\mu_\theta}(\textbf{x}_t(\textbf{x}_0, \epsilon), t)\Big\lVert^2\right] \\
    &= \EX_{\textbf{x}_0, \epsilon}\left[\frac{1}{2{\sigma_t}^2}
    \Big\lVert \frac{\sqrt{\Bar{\alpha}_{t-1}}\beta_t}{1 - \Bar{\alpha}_t}\frac{1}{\sqrt{\Bar{\alpha}_t}}(\textbf{x}_t(\textbf{x}_0, \epsilon) - \sqrt{1 - \Bar{\alpha}_t}\epsilon) + \frac{\sqrt{\alpha_t}(1 - \Bar{\alpha}_{t-1})}{1 - \Bar{\alpha}_t}\textbf{x}_t(x_0, \epsilon) - {\mu_\theta}(\textbf{x}_t(\textbf{x}_0, \epsilon), t)\Big\rVert^2\right]\\
    &= \EX_{\textbf{x}_0, \epsilon}\left[\frac{1}{2{\sigma_t}^2}
    \Big\lVert \left[\frac{\beta_t}{(1 - \Bar{\alpha}_t)\sqrt{\alpha_t}} + \frac{\alpha_t(1 - \Bar{\alpha}_{t - 1})}{\sqrt{\alpha_t}(1 - \Bar{\alpha}_t)}\right]\textbf{x}_t(\textbf{x}_0, \epsilon) - \frac{\beta_t}{\sqrt{1 - \Bar{\alpha}_t}\sqrt{\alpha_t}}\epsilon - {\mu_\theta}(\textbf{x}_t(\textbf{x}_0, \epsilon), t)\Big\rVert^2\right]\\
    &= \EX_{\textbf{x}_0, \epsilon}\left[\frac{1}{2{\sigma_t}^2}
    \Big\lVert \frac{\beta_t + \alpha_t - \Bar{\alpha_t}}{\sqrt{\alpha_t}(1 - \Bar{\alpha}_t)}\textbf{x}_t(\textbf{x}_0, \epsilon) - \frac{\beta_t}{\sqrt{1 - \Bar{\alpha}_t}\sqrt{\alpha_t}}\epsilon - {\mu_\theta}(\textbf{x}_t(\textbf{x}_0, \epsilon), t)\Big\rVert^2\right]\\
    &= \EX_{\textbf{x}_0, \epsilon}\left[\frac{1}{2{\sigma_t}^2}
    \Big\lVert \frac{1}{\sqrt{\alpha_t}}\left[\frac{1 - \alpha_t + \alpha_t - \Bar{\alpha_t}}{(1 - \Bar{\alpha}_t)}\textbf{x}_t(\textbf{x}_0, \epsilon) - \frac{\beta_t}{\sqrt{1 - \Bar{\alpha}_t}}\epsilon\right] - {\mu_\theta}(\textbf{x}_t(\textbf{x}_0, \epsilon), t)\Big\rVert^2\right]\\
    &= \EX_{\textbf{x}_0, \epsilon}\left[\frac{1}{2{\sigma_t}^2}
    \Big\lVert \frac{1}{\sqrt{\alpha_t}}\left[\frac{1 - \alpha_t + \alpha_t - \Bar{\alpha_t}}{(1 - \Bar{\alpha}_t)}\textbf{x}_t(\textbf{x}_0, \epsilon) - \frac{\beta_t}{\sqrt{1 - \Bar{\alpha}_t}}\epsilon\right] - {\mu_\theta}(\textbf{x}_t(\textbf{x}_0, \epsilon), t)\Big\rVert^2\right]\\
    &= \EX_{\textbf{x}_0, \epsilon}\left[\frac{1}{2{\sigma_t}^2}
    \Big\lVert \frac{1}{\sqrt{\alpha_t}}\left[\textbf{x}_t(\textbf{x}_0, \epsilon) - \frac{\beta_t}{\sqrt{1 - \Bar{\alpha}_t}}\epsilon\right] - {\mu_\theta}(\textbf{x}_t(\textbf{x}_0, \epsilon), t)\Big\rVert^2\right]\\
    \end{align*}
}
    \item 
    Instead of training the reverse process to predict the mean, we can train it to predict the noise $\epsilon$. Specifically, using the following parameterization of $\mu_\theta$ in terms of $\epsilon_\theta$ :
    \begin{equation}
        {\mu_\theta}(\textbf{x}_t, t) = {{\Tilde\mu}_t}(\textbf{x}_t, \frac{1}{\sqrt{{\bar\alpha}_t}}(\textbf{x}_t - \sqrt{1 - {\bar\alpha}_t}{\epsilon_\theta}_(\textbf{x}_t))) = \frac{1}{\sqrt{\alpha_t}}(\textbf{x}_t - \frac{\beta_t}{\sqrt{1 - {\bar\alpha}_t}}{\epsilon_\theta}\left(\textbf{x}_t, t)\right)
    \end{equation}
    \textbf{rewrite your answer to problem (3.1) in terms of  $\epsilon$, $\epsilon_\theta$, and $\textbf{x}_0$ only (no $\mu_\theta$ or $\textbf{x}_t$).}

    % Answer:
\textcolor{blue}{
    \textbf{Solution: } 
    \begin{align*}
    L_{t-1} - C &= \EX_{x_0, \epsilon}\left[\frac{1}{2{\sigma_t}^2}
    \Big\lVert \frac{1}{\sqrt{\alpha_t}}\left[\textbf{x}_t(\textbf{x}_0, \epsilon) - \frac{\beta_t}{\sqrt{1 - \Bar{\alpha}_t}}\epsilon\right] - {\mu_\theta}(\textbf{x}_t(\textbf{x}_0, \epsilon), t)\Big\rVert^2\right] \\
    &= \EX_{\textbf{x}_0, \epsilon}\left[\frac{1}{2{\sigma_t}^2}
    \Big\lVert \frac{1}{\sqrt{\alpha_t}}\left[\textbf{x}_t(\textbf{x}_0, \epsilon) - \frac{\beta_t}{\sqrt{1 - \Bar{\alpha}_t}}\epsilon\right] - \frac{1}{\sqrt{\alpha_t}}\left(\textbf{x}_t(\textbf{x}_0, \epsilon) - \frac{\beta_t}{\sqrt{1 - \Bar{\alpha}_t}}\epsilon_\theta(\textbf{x}_t(\textbf{x}_0, \epsilon), t)\right)\Big\rVert^2\right] \\
    &= \EX_{\textbf{x}_0, \epsilon}\left[\frac{1}{2{\sigma_t}^2\alpha_t}
    \Big\lVert - \frac{\beta_t}{\sqrt{1 - \Bar{\alpha}_t}}\epsilon +  \frac{\beta_t}{\sqrt{1 - \Bar{\alpha}_t}}\epsilon_\theta(\textbf{x}_t(\textbf{x}_0, \epsilon), t)\Big\rVert^2\right] \\
    &= \EX_{\textbf{x}_0, \epsilon}\left[\frac{\beta_t^2}{2{\sigma_t}^2\alpha_t(1 - \Bar{\alpha}_t)}
    \Big\lVert \epsilon - \epsilon_\theta(\textbf{x}_t(\textbf{x}_0, \epsilon), t)\Big\rVert^2\right] \\
    &= \EX_{\textbf{x}_0, \epsilon}\left[\frac{\beta_t^2}{2{\sigma_t}^2\alpha_t(1 - \Bar{\alpha}_t)}
    \Big\lVert \epsilon - \epsilon_\theta(\sqrt{\Bar{\alpha}_t}\textbf{x}_0 + \sqrt{1 - \Bar{\alpha}_t}\epsilon, t)\Big\rVert^2\right]
    \end{align*}}
\end{enumerate}


\section{Predicting Mean vs. Predicting Noise}

As shown in the prior questions, there are often multiple choices of loss functions and different parameterizations to choose from, whether to use for training or to gauge how effective one model might be over another.

Here, we'll look at two specific choices: one involving the mean of the distribution over the timesteps of the diffusion process, and the other involving the noise that was added to the input as a result of diffusion.

We'll consider just the loss functions themselves for this question, as the process of training denoising models will be covered in the last question of this homework.

\begin{enumerate}
    \item
        \textbf{Implement both loss functions} in the \verb|loss_func_comp.ipynb| Jupyter notebook, and compare their computation times.
        
    % Answer:
    \textcolor{blue}{
        \textbf{Solution: } See the Jupyter notebook for the coding solutions.
    }
        
    \item
        \textbf{Comment on the relative speeds of these loss functions. How might this impact which function you'd want to use in practice?}

    % Answer:
    \textcolor{blue}{
        \textbf{Solution: } Although there may be some inconsistencies in timing, you should notice that the noise loss generally takes less time to compute than the mean loss. While these raw computations can be optimized, whether using JAX's jit functionality or otherwise,it's worth noting that the noise loss is also more commonly used because it lends itself more readily to other approximations outside the scope of this homework. Additionally, though we don't explicitly cover it here, using the loss of the noise and therefore training a model to predict the noise (as opposed to the mean) has been shown in the paper (see reference [1]) to quantitatively have better performance in training as well.
    }
\end{enumerate}

\section{Code: Train and Observe}
\begin{enumerate}
    \item
        \textbf{Complete all parts of 
        denoising.ipynb.}
        
    % Answer:
    \textcolor{blue}{
        \textbf{Solution: } See the Jupyter notebook for the coding solutions.
    }
    
    \item 
        Compare the states from the forward process and backward process. \textbf{What do you observe? Note down your observations in the written part of this homework.}
    
    % Answer:
    \textcolor{blue}{
        \textbf{Solution: } For the reconstruction visualizations, the samples that we reconstructed look similar to the original samples, the single dot image, that were diffused for one time step. However, the reconstructed samples also carry some noise from the i.i.d. randomly sampled Gaussian noise that was not completely removed.
    }
    
    \textcolor{blue}{
        For the generation visualizations, the generated samples look similar to samples from the original distribution (the single dot image), which is great. It's also clear that the Gaussian noise that the generation started off with were rather different from the original distribution, so this means the model was able to generate something similar to our original interesting distribution from noise fairly well. However, some samples don't look as close to the original distribution, though they do look \textit{closer} than the original noise - this is likely because the model could still be trained for longer in order for it to know how to move these randomly sampled noise images towards the original distribution.
    }
\end{enumerate}

\section{Homework Process and Study Group}
\begin{enumerate}
    \item
        \textbf{What sources did you use to work through this homework?}
    \item
        \textbf{Did you work with anyone on this homework? If so, please list their names and Cal 1 ID's here.}
    \item
        \textbf{About how many hours did this homework take you?}
\end{enumerate}

\section*{References}
\beginrefs
\bibentry{1}{\sc Jonathan Ho}, {\sc Ajay Jain}, {\sc Pieter Abbeel},
Denoising Diffusion Probabilistic Models, 
{\it Advances in Neural Information Processing Systems 33 (NeurIPS)\/} (2020).
\bibentry{2}{\sc The JAX Authors}, {\sc Google}, 
JAX reference documentation, \\
{\it https://jax.readthedocs.io/en/latest/index.html\/} (2020).


\endrefs

\end{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%